{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1609,"status":"ok","timestamp":1670457381454,"user":{"displayName":"Henry Savich","userId":"10317851829012013120"},"user_tz":360},"id":"CkfNLr3bwM1d","outputId":"ac564285-d59b-49ce-de78-3718b3b0fc35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Connected to a GPU\n","Using a high-RAM runtime: 89.6 gigabytes of available RAM\n"]}],"source":["# check system specs\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print('Connected to a GPU')\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))\n","else:\n","  print('Using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRhUTne0pj1Z"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17577,"status":"ok","timestamp":1670457399008,"user":{"displayName":"Henry Savich","userId":"10317851829012013120"},"user_tz":360},"id":"abnMMJxtptv1","outputId":"60fe5683-d3b2-4bf0-d69d-285b57bbd788"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670457399009,"user":{"displayName":"Henry Savich","userId":"10317851829012013120"},"user_tz":360},"id":"MZHDFnTQpxb2","outputId":"c65cd94d-6f47-4583-f454-d52d110cc9ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1WHLBzPq6pt_F7mh3d3goIQl4MwYlTfIh/ml2_project\n"]}],"source":["# note: place shortcut to shared project folder in google drive root directory\n","%cd /content/gdrive/MyDrive/ml2_project"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RoEB_guxuHF5"},"outputs":[],"source":["!pip install sentence_transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gr0Cmwgpj1b"},"outputs":[],"source":["# load models\n","\n","from sentence_transformers import SentenceTransformer\n","import torch\n","\n","# base_model = SentenceTransformer('all-MiniLM-L12-v2')\n","# base_model.save('./all-MiniLM-L12-v2')\n","base_model = SentenceTransformer('./models/all-MiniLM-L12-v2')\n","base_model = base_model.to(torch.device('cuda')) # use GPU\n","\n","ft_final_model = SentenceTransformer('./models/finetune_mnr_final')\n","ft_final_model = ft_final_model.to(torch.device('cuda')) # use GPU\n"]},{"cell_type":"code","source":[],"metadata":{"id":"r9zC1A4vOKKY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Example Embedding without SentenceTransformers\n"],"metadata":{"id":"jSfWLPPvONUQ"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","import torch.nn.functional as F\n","\n","#Mean Pooling - Take attention mask into account for correct averaging\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","\n","# Sentences we want sentence embeddings for\n","sentences = ['This is an example sentence', 'Each sentence is converted']\n","\n","# Load model from HuggingFace Hub\n","tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n","model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n","\n","# Tokenize sentences\n","encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n","\n","# Compute token embeddings\n","with torch.no_grad():\n","    model_output = model(**encoded_input)\n","\n","# Perform pooling\n","sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","\n","# Normalize embeddings\n","sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n","\n","print(\"Sentence embeddings:\")\n","print(sentence_embeddings)"],"metadata":{"id":"Y27khiIhOIXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTaJtyPe5lrO"},"source":["### Small Dataset\n","Load small dataset and append embeddings from base model and final fine-tuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COEuIZ33pj1c"},"outputs":[],"source":["sds = pd.read_csv('data/small_dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GzP3isbpj1c"},"outputs":[],"source":["embeddings_base = base_model.encode(sds['lyrics'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vh7RWiP62KO"},"outputs":[],"source":["embeddings_ft_final = ft_final_model.encode(sds['lyrics'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rizQKlrpj1c"},"outputs":[],"source":["sds['embeddings_base'] = list(embeddings_base)\n","sds['embeddings_ft_final'] = list(embeddings_ft_final)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWoEBLqzxGVt"},"outputs":[],"source":["sds.to_csv('data/small_dataset_w_embeddings.csv')"]},{"cell_type":"markdown","metadata":{"id":"y7LMXs7T5pXa"},"source":["### Large Dataset\n","Load full dataset and append embeddings from base model and final fine-tuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_EM3fXl5oSs"},"outputs":[],"source":["df = pd.read_csv('data/clean_dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oj4hh8EV5sAv"},"outputs":[],"source":["embeddings_base = base_model.encode(df['lyrics'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygGDtD1X66Ku"},"outputs":[],"source":["embeddings_ft_final = ft_final_model.encode(df['lyrics'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBZUqYpd5sGR"},"outputs":[],"source":["df['embeddings_base'] = list(embeddings_base)\n","df['embeddings_ft_final'] = list(embeddings_ft_final)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yC-6asu-5sKa"},"outputs":[],"source":["df.to_csv('data/clean_dataset_w_embeddings.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0axynuZ5sQF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.8.5 ('base')","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}